from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Mapping, Protocol, Sequence

import numpy as np
import torch
from _typeshed import Incomplete
from numpy.typing import NDArray

from .exceptions import BackendError as BackendError

ArrayLike: Incomplete

class WeightStore(Protocol):
    def resolve(self, name: str) -> Any: ...

@dataclass
class InMemoryWeightStore:
    weights: dict[str, Any]
    def resolve(self, name: str) -> Any: ...
    def fingerprint(self) -> dict[str, Any]: ...

@dataclass
class ShardingPolicy:
    strategy: str = ...
    mesh: Any | None = ...
    attributes: dict[str, Any] = field(default_factory=dict)
    def materialize(self, name: str, value: Any) -> Any: ...
    def fingerprint(self) -> dict[str, Any]: ...

@dataclass
class QuantizationPolicy:
    mode: str = ...
    bits: int = ...
    group_size: int = ...
    def apply(self, name: str, value: NDArray[Any]) -> NDArray[Any]: ...
    def fingerprint(self) -> dict[str, Any]: ...

@dataclass
class LoRAPolicy:
    rank: int
    alpha: float = ...
    adapters: dict[str, tuple[NDArray[Any], NDArray[Any]]] = field(default_factory=dict)
    def apply(self, name: str, base: NDArray[Any]) -> NDArray[Any]: ...
    def fingerprint(self) -> dict[str, Any]: ...

@dataclass
class QuantizedSpec:
    mode: str
    scale: NDArray[Any]
    zero_point: NDArray[Any] | None = ...
    dtype: str = ...
    group_size: int | None = ...
    @classmethod
    def from_mapping(cls, mapping: Mapping[str, Any], *, base_path: Path | None, mmap: bool, mmap_threshold: int | None, strict: bool) -> QuantizedSpec: ...
    def is_active(self) -> bool: ...
    def __post_init__(self) -> None: ...
    def dequantize_numpy(self, values: NDArray[Any]) -> NDArray[Any]: ...
    def dequantize_torch(self, tensor: torch.Tensor) -> torch.Tensor: ...

@dataclass
class LoRAAdapter:
    name: str
    up: NDArray[Any]
    down: NDArray[Any]
    alpha: float = ...
    @property
    def rank(self) -> int: ...
    def __post_init__(self) -> None: ...
    def merge_numpy(self, base: NDArray[Any]) -> NDArray[Any]: ...
    def merge_torch(self, base: torch.Tensor) -> torch.Tensor: ...

@dataclass
class LoRASpec:
    slot: str | None
    merge: str
    adapters: dict[str, LoRAAdapter]
    default: str | None
    @classmethod
    def from_mapping(cls, mapping: Mapping[str, Any], *, base_path: Path | None, mmap: bool, mmap_threshold: int | None, strict: bool) -> LoRASpec: ...

@dataclass
class ResolvedLoRA:
    merge: str
    adapter: LoRAAdapter | None = ...
    def merge_numpy(self, base: NDArray[Any]) -> NDArray[Any]: ...
    def merge_torch(self, base: torch.Tensor) -> torch.Tensor: ...

@dataclass
class PrefetchSpec:
    window: int = ...
    group: str | None = ...
    neighbors: tuple[str, ...] = ...
    order: int = ...
    @classmethod
    def from_mapping(cls, mapping: Mapping[str, Any] | None, default_order: int) -> PrefetchSpec: ...

@dataclass
class WeightShard:
    path: Path
    axis: int | None = ...
    dtype: np.dtype[Any] | None = ...
    @classmethod
    def from_mapping(cls, mapping: Mapping[str, Any], *, base_path: Path | None) -> WeightShard: ...

@dataclass
class WeightManifestEntry:
    name: str
    path: Path | None
    value: NDArray[Any] | None
    dtype: np.dtype[Any]
    shards: tuple[WeightShard, ...]
    shard_axis: int | None
    quant: QuantizedSpec | None
    lora: LoRASpec | None
    scale: NDArray[Any] | None
    prefetch: PrefetchSpec
    placement: str | None
    metadata: dict[str, Any]
    @classmethod
    def from_mapping(cls, mapping: Mapping[str, Any], *, base_path: Path | None, mmap: bool, mmap_threshold: int | None, strict: bool, default_order: int) -> WeightManifestEntry: ...

@dataclass
class ResolvedWeight:
    name: str
    data: NDArray[Any]
    dtype: np.dtype[Any]
    quant: QuantizedSpec | None = ...
    scale: NDArray[Any] | None = ...
    lora: ResolvedLoRA | None = ...
    placement: str | None = ...
    metadata: dict[str, Any] = field(default_factory=dict)
    footprint: int | None = ...
    def materialize(self, *, backend: str, device: Any | None = None) -> Any: ...
    def footprint_bytes(self) -> int: ...

class ManifestWeightStore(WeightStore):
    cache_bytes: Incomplete
    mmap_mode: Incomplete
    mmap_threshold: Incomplete
    strict_mode: Incomplete
    def __init__(self, manifest: str | Path | Mapping[str, Any] | Sequence[Mapping[str, Any]], *, base_path: str | Path | None = None, cache_bytes: int = ..., mmap_mode: bool = True, mmap_threshold_bytes: int | None = ..., strict: bool = False) -> None: ...
    def resolve(self, name: str) -> ResolvedWeight: ...
    def available_adapters(self, slot: str) -> Sequence[str]: ...
    def activate_adapter(self, slot: str, adapter: str | None) -> None: ...
    def fingerprint(self) -> dict[str, Any]: ...
    def export_state(self) -> dict[str, Any]: ...

@dataclass
class RuntimePolicies:
    weight_store: WeightStore | None = ...
    sharding: ShardingPolicy | None = ...
    quantization: QuantizationPolicy | None = ...
    lora: LoRAPolicy | None = ...
    output_root: Path | None = ...
    def apply(self, name: str, value: NDArray[Any]) -> NDArray[Any]: ...
    def materialize_weight(self, name: str, payload: Any, *, backend: str, device: Any | None = None) -> Any: ...
    def fingerprint(self) -> dict[str, Any]: ...
    def resolve_output_path(self, path: str | Path) -> Path: ...
